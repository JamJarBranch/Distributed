# 分布式爬虫

## celery

开启一个终端执行celery -A tasks beat(需注意路径问题，在与任务文件的同级目录下执行，tasks为文件名)
开启另外一个终端执行celery -A tasks worker --pool=solo -l info

### 参数配置

```
# CELERY_DEFAULT_QUEUE	默认的队列名称，当没有为task特别指定队列时，采用此队列
# CELERY_BROKER_URL	消息代理，用于发布者传递消息给消费者，推荐RabbitMQ
# CELERY_RESULT_BACKEND	后端，用于存储任务执行结果，推荐redis
# CELERY_TIMEZONE	时区设置，计划任务需要，推荐 Asia/Shanghai
# CELERYBEAT_SCHEDULE	Celery计划任务设定
# CELERY_QUEUES	Celery队列设定
# CELERY_ROUTES	Celery路由设定，用于给不同的任务指派不同的队列
```

**指定配置文件**

```
app.config_from_object("指定配置文件")
```

### 任务的调用

delay()	是apply_async()方法的快捷方式	--->  返回的是 AsyncResult实例 

apply_async() 能指定执行选项， 比如运行时间、应该发送的队列等等

- eta：指定任务执行时间，类型为datetime时间类型；

- countdown：倒计时,单位秒，浮点类型；

- expires：任务过期时间，如果任务在超过过期时间还未执行则回收任务，浮点类型获取datetime类型；

- retry：任务执行失败时候是否尝试，布尔类型。；

- serializer：序列化方案，支持pickle、json、yaml、msgpack；

- priority：任务优先级，有0～9优先级可设置，int类型；

- retry_policy：任务重试机制。类型是dict

  - ```
    max_retries:最大重试次数
    
    interval_start:重试等待时间
    
    interval_step:每次重试叠加时长，假设第一重试等待1s，第二次等待1＋n秒
    
    interval_max:最大等待时间
    ```

**任务异常**

可以通过 result.get() 来传播，不希望传播时通过 propagete=False 属性禁用

**任务的状态**

PENDING -> STARTED -> SUCCESS

STARTED 只有在task_track_started设置启用或者@task(track_started=True)选项设置的时候才会被记录下来

**检测任务的成功或失败**

failed()	successful()

**任务流的设置**

signature	-->	将任务调用的签名传递给另一个进程或者另一个函数的参数

签名以某种方式包装了单一任务调用的参数和执行选项，以便将其传递给函数，甚至序列化后发送

### 基本体

基本体本身就是签名对象， 可以任何多种方式组合起来组成复杂的工作流

group、chain、chord、map、starmap、chunks

**group**

 并行执行组内的每个任务 

一个group同时调用任务列表，返回一个特殊结果实例，这样可以以组的形式检查结果，并按顺序检索返回值

```
group(signature, signature, ...)
```

**chain**

 一个任务需要等待上个任务执行完才能执行 

任务可以被相互连接起来，这样在一个任务返回后另一个任务被调用

**chord**

 分为header和body两个部分，会先执行header在将header的结果传给body执行 

是一个有返回值的group

**chunks**

 按照任务个数分组，并不是并发执行 



### 进阶

装饰器将一个正常的函数修饰为一个 celery task 对象。

### 内置钩子函数

 执行任务时候，提供了钩子方法用于在任务执行完成时候进行对应的操作 

 Task源码中提供了很多状态钩子函数如：on_success(成功后执行)、on_failure(失败时候执行)、on_retry(任务重试时候执行)、after_return(任务返回时候执行) 

```python
@app.task(base=MyTask, )
def add(x, y):
```

将任务绑定为实例方法（方便引用）

```python
@app.task(name='Demo.tasks.add',bind=True)
def add(self,x, y):
```

 任务里的self和类方法里的self相似都代表是自己本身，都是可不传的参数，可获取到与自身有关的所有参数 

### 任务回调

```
self.update_state(state="PROGRESS",)
```

### 定期/周期任务

在配置中配置好周期任务，运行一个周期任务触发器(beat)即可

```python
CELERYBEAT_SCHEDULE = {
    'tasks': {
        'task': 'tasks.period_task',
        'schedule': crontab(minute="*/1"),
    },
# schedule就是定时时间，分别可以使用crontab,timedelta都可以配置时间
```

定时任务涉及到 datetime 需要再配置中 加入时区信息，默认 utc

```
CELERY_TIMEZONE = 'Asia/Shanghai'
```

### 链式任务

用异步回调的方式进行链式任务的调用

链式任务中前一个任务的返回值 默认是下一个任务的输入值之一。

不想让返回值做默认参数可以用 si() 或者 s(immutable=True) 的方式调用 。

 `s()` 是方法 `celery.signature()` 的快捷调用方式

signature 具体作用就是生成一个包含调用任务及其调用参数与其他信息的对象，个人感觉有点类似偏函数的概念：先不执行任务，而是把任务与任务参数存起来以供其他地方调用。

### 管理与监控

 flower组件不仅仅提供监控功能，还提供HTTP API可实现对woker和task的管理 

```
# 启动
flower -A project --port=5555   
# -A ：项目目录
#--port 指定端口
```

API的使用

```
curl http://127.0.0.1:5555/api/workers
```



## 消息队列

队列模型和主题模型(发布订阅模型)

**队列模型**

 ![img](https://mmbiz.qpic.cn/mmbiz_jpg/A1HKVXsfHNkJWKnS4gz3yiarWOQ8TUY3W7dp9FycpwlwHQO9nGIxdgibuyCMlic1lu980okdv41cW5xbouAZZ6Y5A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1) 

一个消息发送给多个消费者， 单个队列不可以满足需求

解决办法一： 让 Producer 生产消息放入多个队列中，然后每个队列去对应每一个消费者。 

问题： 创建多个队列并且复制多份消息是会很影响资源和性能的； 生产者需要知道具体消费者个数然后去复制对应数量的消息队列，违背了解耦的原则

解决办法二：发布订阅模型(主题模型)

**发布订阅模型**

 消息的生产者称为发布者（Publisher），消息的消费者称为订阅者（Subscriber），存放消息的容器称为主题（Topic） 

 ![img](https://mmbiz.qpic.cn/mmbiz_jpg/A1HKVXsfHNkJWKnS4gz3yiarWOQ8TUY3Wvic6smiaicIc7ZdfCsp4a8HJ4LbnNJDyfZqEB5IVj7jmWuIhbldo1LoeA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1) 

好处：异步、解耦、削峰

坏处：保持HA需要搞集群，系统的复杂度上升

**重复消息**（生产者 发送失败执行重试可能产生重复的信息， 消费端处理失败请求重发也会产生重复的消息 ）

**顺序消费**（发布订阅模型中主题是没有顺序的）

**分布式事务**( 同一个系统中我们一般会使用事务来进行解决 ,  不同系统中如何保证事务呢？)

**解决消息堆积问题 **(消费者消费很慢或者生产者生产消息很快，会将消息堆积在消息队列中)

## rabbitmq

**关于一些概念**

```
Exchange：Exchange是消息队列中一个核心的概念，一条消息进行消息队列后**首先**会进入Exchange。
Queue：Queue是Worker等待处理的任务队列。
routing_key：routing_key决定了Exchange中的消息是如何发生给Queue的。即其决定了哪些消息插入哪个队列。
路由：此处的路由指的是任务生产端的任务应该绑定什么样的routing_key以及应该发送至哪个Queue中。
```

### 发布订阅模型

![img](https://mmbiz.qpic.cn/mmbiz_jpg/A1HKVXsfHNkJWKnS4gz3yiarWOQ8TUY3WWh5SxAePVia1QzRSHg0DuTc6yIuc0BjOszAnNicMeQJW1XgMXW97icREA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1) 

生产者组 一般生产相同的消息；消费者组一般消费相同的消息

每个主题有多个队列， 集群模式下 一个消费者集群多台机器消费一个topic的多个队列。

**一个队列只会被一个消费者消费**。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费 

每个消费组在每个队列上 维护一个消费位置。

在存在多个消费者组的情况下， 消息被一个消费者组消费完之后是不会删除的（因为其它消费者组也需要呀） ， 它仅仅是为每个消费者组维护一个消费位移（offset），每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了 

一个主题维护多个队列：(提高并发能力)



1、轮询接收消息

2、消息确认为了防止消息丢失，RabbitMQ提供了消息响应（acknowledgments）。消费者会通过一个ack（响应），告诉RabbitMQ已经收到并处理了某条消息，然后RabbitMQ就会释放并删除这条消息。如果消费者（consumer）挂掉了，没有发送响应，RabbitMQ就会认为消息没有被完全处理，然后重新发送给其他消费者（consumer）。这样，及时工作者（workers）偶尔的挂掉，也不会丢失消息。

消息响应默认auto_ack=False, 不自动确认消息

确认需要发送确认消息：在回调callback中加入basic_ack

channel.basic_ack(delivery_tag = method.delivery_tag)

如果auto_ack设置为True，而忘记basic_ack消息确认，消息在程序退出之后就会重新发送，如果不及时释放没响应的消息，RabbitMQ就会占用越来越多的内存。排除这个错误可以使用 rabbitmqctl list_queues name messages_ready messages_unacknowledged

3、消息持久化

消息持久化必须把“队列”和“消息”设为持久化

队列声明持久化 durable=True

一个消息队列被声明过一次后，rabbitmq不允许使用不同的参数重新定义队列

消息声明持久化 delivery_mode=2

消息存在内存里面，所以消息也要持久化，从内存转存到硬盘

将publish生产者发送消息时候消息属性 delivery_mode=2

4、设置客户端QOS

开启客户端最大的未处理消息队列大小

5、发布订阅模式

消息是被依次发送给消费者，即是消息只会被发送给一个消费者，除非开启确认机制时处理失败了， 一个消息发送给多个消费者发布者（producer）只需要把消息发送给一个交换机（exchange）。

rabbitmq拥有一个默认交换机 即是 空字符串("")交换机非常简单，它一边从发布者方接收消息，一边把消息推送到队列。

交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息。这些规则是通过交换机类型（exchange type）来定义的

交换机类型：直连交换机（direct）-- 一对一， 之前使用的就是这个；主题交换机（topic）-- 模糊匹配，需要符合匹配规则；headers（头交换机）扇型交换机（fanout）-- 进行消息广播

消息将会根据指定的 routing_key 分发到指定的队列主题交换机 

模糊匹配：* (星号) 用来表示一个单词.# (井号) 用来表示任意数量（零个或多个）单词。



**pika提供与rabbitmq建立连接的方式**

```
pika.adapters.asyncio_connection.AsyncioConnection - 用于python 3 AsyncIO的I/O异步模式
pika.BlockingConnection - 同步模式， 简单易用
pika.SelectConnection - 没有第三方依赖包的异步模式
pika.adapters.tornado_connection.TornadoConnection - 基于Tornado 的异步IO请求模式
pika.adapters.twisted_connection.TwistedProtocolConnection - 基于Twisted’的异步IO请求模式
```


cluster集群功能
对于集群的连接与单节点连接稍微有点不一样，
如果集群依然只是用单节点的连接方式，则pika只连接到一个节点，
但节点宕机， 服务异常等服务不可用时无法实现故障转移功能。
因此需要配置多个节点，使得节点异常时，能够在另外一个node上重连，并继续提供服务
实现重试功能需设置connection_attempts 和 retry_delay， 重试发生在在所有给定的节点都连接失败后

对于非阻塞适配器（非BlockingConnection）

如pika.selectconnection和pika.adapter s.asyncio_connection.asynciioconnection，
可以通过连接适配器的create_connection（）类方法使用多个连接参数实例请求连接。



## redis

### 关于redis分布式锁

    原子性概念:一个事务是一个不可分割的最小工作单位,要么都成功要么都失败。
    原子操作是指你的一个业务逻辑必须是不可拆分的. 处理一件事情要么都成功，要么都失败，原子不可拆分
    pipeline是非原子操作
    pipeline需要服务端和客户端共同完成
    
    pipeline只适用于那些不需要获取同步结果的场景
    一般使用pipeline时，需要自己保证执行命令的数据安全性
    
    pipeline是多条命令的组合，为了保证它的原子性，redis提供了简单的事务。
    一组需要一起执行的命令放到multi和exec两个命令之间，其中multi代表事务开始，exec代表事务结束。
    停止事务 discard
    命令错误或者语法不正确 会导致事务不能正常结束；
    运行错误，语法正确，但类型错误，事务可以正常结束
    
    使用 watch 后，multi失效，事务失效
    WATCH 的机制：
    在事务EXEC命令执行时，Redis会检查被WATCH的key，只有被WATCH的key从WATCH起始时至今没有发生过变更，EXEC才会被执行。
    如果WATCH的key在WATCH命令到EXEC命令之间发生过变化，则EXEC命令会返回失败
    
    redis提供了简单的事务，不支持事务回滚
```
SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。
expire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。
ttl 求剩余的过期时间
```